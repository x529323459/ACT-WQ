RTDETR(
  (backbone): PResNet(
    (conv1): Sequential(
      (conv1_1): ConvNormLayer(
        (conv): ConvReLU2d(
          (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
          (1): ReLU(inplace=True)
        )
        (norm): Identity()
        (act): Identity()
      )
      (conv1_2): ConvNormLayer(
        (conv): ConvReLU2d(
          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): ReLU(inplace=True)
        )
        (norm): Identity()
        (act): Identity()
      )
      (conv1_3): ConvNormLayer(
        (conv): ConvReLU2d(
          (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): ReLU(inplace=True)
        )
        (norm): Identity()
        (act): Identity()
      )
    )
    (res_layers): ModuleList(
      (0): Blocks(
        (blocks): ModuleList(
          (0): BasicBlock(
            (short): ConvNormLayer(
              (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
              (norm): Identity()
              (act): Identity()
            )
            (branch2a): ConvNormLayer(
              (conv): ConvReLU2d(
                (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
                (1): ReLU(inplace=True)
              )
              (norm): Identity()
              (act): Identity()
            )
            (branch2b): ConvNormLayer(
              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              (norm): Identity()
              (act): Identity()
            )
            (act): ReLU(inplace=True)
          )
          (1): BasicBlock(
            (branch2a): ConvNormLayer(
              (conv): ConvReLU2d(
                (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
                (1): ReLU(inplace=True)
              )
              (norm): Identity()
              (act): Identity()
            )
            (branch2b): ConvNormLayer(
              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              (norm): Identity()
              (act): Identity()
            )
            (act): ReLU(inplace=True)
          )
        )
      )
      (1): Blocks(
        (blocks): ModuleList(
          (0): BasicBlock(
            (short): Sequential(
              (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)
              (conv): ConvNormLayer(
                (conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))
                (norm): Identity()
                (act): Identity()
              )
            )
            (branch2a): ConvNormLayer(
              (conv): ConvReLU2d(
                (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
                (1): ReLU(inplace=True)
              )
              (norm): Identity()
              (act): Identity()
            )
            (branch2b): ConvNormLayer(
              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              (norm): Identity()
              (act): Identity()
            )
            (act): ReLU(inplace=True)
          )
          (1): BasicBlock(
            (branch2a): ConvNormLayer(
              (conv): ConvReLU2d(
                (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
                (1): ReLU(inplace=True)
              )
              (norm): Identity()
              (act): Identity()
            )
            (branch2b): ConvNormLayer(
              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              (norm): Identity()
              (act): Identity()
            )
            (act): ReLU(inplace=True)
          )
        )
      )
      (2): Blocks(
        (blocks): ModuleList(
          (0): BasicBlock(
            (short): Sequential(
              (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)
              (conv): ConvNormLayer(
                (conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))
                (norm): Identity()
                (act): Identity()
              )
            )
            (branch2a): ConvNormLayer(
              (conv): ConvReLU2d(
                (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
                (1): ReLU(inplace=True)
              )
              (norm): Identity()
              (act): Identity()
            )
            (branch2b): ConvNormLayer(
              (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              (norm): Identity()
              (act): Identity()
            )
            (act): ReLU(inplace=True)
          )
          (1): BasicBlock(
            (branch2a): ConvNormLayer(
              (conv): ConvReLU2d(
                (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
                (1): ReLU(inplace=True)
              )
              (norm): Identity()
              (act): Identity()
            )
            (branch2b): ConvNormLayer(
              (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              (norm): Identity()
              (act): Identity()
            )
            (act): ReLU(inplace=True)
          )
        )
      )
      (3): Blocks(
        (blocks): ModuleList(
          (0): BasicBlock(
            (short): Sequential(
              (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)
              (conv): ConvNormLayer(
                (conv): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1))
                (norm): Identity()
                (act): Identity()
              )
            )
            (branch2a): ConvNormLayer(
              (conv): ConvReLU2d(
                (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
                (1): ReLU(inplace=True)
              )
              (norm): Identity()
              (act): Identity()
            )
            (branch2b): ConvNormLayer(
              (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              (norm): Identity()
              (act): Identity()
            )
            (act): ReLU(inplace=True)
          )
          (1): BasicBlock(
            (branch2a): ConvNormLayer(
              (conv): ConvReLU2d(
                (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
                (1): ReLU(inplace=True)
              )
              (norm): Identity()
              (act): Identity()
            )
            (branch2b): ConvNormLayer(
              (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              (norm): Identity()
              (act): Identity()
            )
            (act): ReLU(inplace=True)
          )
        )
      )
    )
  )
  (decoder): RTDETRTransformer(
    (input_proj): ModuleList(
      (0-2): 3 x Sequential(
        (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
        (norm): Identity()
      )
    )
    (decoder): TransformerDecoder(
      (layers): ModuleList(
        (0-2): 3 x TransformerDecoderLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (dropout1): Dropout(p=0.0, inplace=False)
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (cross_attn): MSDeformableAttention(
            (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
            (attention_weights): Linear(in_features=256, out_features=96, bias=True)
            (value_proj): Linear(in_features=256, out_features=256, bias=True)
            (output_proj): Linear(in_features=256, out_features=256, bias=True)
          )
          (dropout2): Dropout(p=0.0, inplace=False)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (linear1): Linear(in_features=256, out_features=1024, bias=True)
          (dropout3): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=1024, out_features=256, bias=True)
          (dropout4): Dropout(p=0.0, inplace=False)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
      )
    )
    (denoising_class_embed): Embedding(81, 256, padding_idx=80)
    (query_pos_head): MLP(
      (layers): ModuleList(
        (0): Linear(in_features=4, out_features=512, bias=True)
        (1): Linear(in_features=512, out_features=256, bias=True)
      )
      (act): ReLU(inplace=True)
    )
    (enc_output): Sequential(
      (0): Linear(in_features=256, out_features=256, bias=True)
      (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (enc_score_head): Linear(in_features=256, out_features=80, bias=True)
    (enc_bbox_head): MLP(
      (layers): ModuleList(
        (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
        (2): Linear(in_features=256, out_features=4, bias=True)
      )
      (act): ReLU(inplace=True)
    )
    (dec_score_head): ModuleList(
      (0-2): 3 x Linear(in_features=256, out_features=80, bias=True)
    )
    (dec_bbox_head): ModuleList(
      (0-2): 3 x MLP(
        (layers): ModuleList(
          (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=4, bias=True)
        )
        (act): ReLU(inplace=True)
      )
    )
  )
  (encoder): HybridEncoder(
    (input_proj): ModuleList(
      (0): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))
        (1): Identity()
      )
      (1): Sequential(
        (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
        (1): Identity()
      )
      (2): Sequential(
        (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
        (1): Identity()
      )
    )
    (encoder): ModuleList(
      (0): TransformerEncoder(
        (layers): ModuleList(
          (0): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=1024, bias=True)
            (dropout): Dropout(p=0.0, inplace=False)
            (linear2): Linear(in_features=1024, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.0, inplace=False)
            (dropout2): Dropout(p=0.0, inplace=False)
            (activation): GELU(approximate='none')
          )
        )
      )
    )
    (lateral_convs): ModuleList(
      (0-1): 2 x ConvNormLayer(
        (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
        (norm): Identity()
        (act): SiLU(inplace=True)
      )
    )
    (fpn_blocks): ModuleList(
      (0-1): 2 x CSPRepLayer(
        (conv1): ConvNormLayer(
          (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))
          (norm): Identity()
          (act): SiLU(inplace=True)
        )
        (conv2): ConvNormLayer(
          (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))
          (norm): Identity()
          (act): SiLU(inplace=True)
        )
        (bottlenecks): Sequential(
          (0): RepVggBlock(
            (conv1): ConvNormLayer(
              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              (norm): Identity()
              (act): Identity()
            )
            (conv2): ConvNormLayer(
              (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
              (norm): Identity()
              (act): Identity()
            )
            (act): SiLU(inplace=True)
          )
          (1): RepVggBlock(
            (conv1): ConvNormLayer(
              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              (norm): Identity()
              (act): Identity()
            )
            (conv2): ConvNormLayer(
              (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
              (norm): Identity()
              (act): Identity()
            )
            (act): SiLU(inplace=True)
          )
          (2): RepVggBlock(
            (conv1): ConvNormLayer(
              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              (norm): Identity()
              (act): Identity()
            )
            (conv2): ConvNormLayer(
              (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
              (norm): Identity()
              (act): Identity()
            )
            (act): SiLU(inplace=True)
          )
        )
        (conv3): ConvNormLayer(
          (conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))
          (norm): Identity()
          (act): SiLU(inplace=True)
        )
      )
    )
    (downsample_convs): ModuleList(
      (0-1): 2 x ConvNormLayer(
        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (norm): Identity()
        (act): SiLU(inplace=True)
      )
    )
    (pan_blocks): ModuleList(
      (0-1): 2 x CSPRepLayer(
        (conv1): ConvNormLayer(
          (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))
          (norm): Identity()
          (act): SiLU(inplace=True)
        )
        (conv2): ConvNormLayer(
          (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))
          (norm): Identity()
          (act): SiLU(inplace=True)
        )
        (bottlenecks): Sequential(
          (0): RepVggBlock(
            (conv1): ConvNormLayer(
              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              (norm): Identity()
              (act): Identity()
            )
            (conv2): ConvNormLayer(
              (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
              (norm): Identity()
              (act): Identity()
            )
            (act): SiLU(inplace=True)
          )
          (1): RepVggBlock(
            (conv1): ConvNormLayer(
              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              (norm): Identity()
              (act): Identity()
            )
            (conv2): ConvNormLayer(
              (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
              (norm): Identity()
              (act): Identity()
            )
            (act): SiLU(inplace=True)
          )
          (2): RepVggBlock(
            (conv1): ConvNormLayer(
              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              (norm): Identity()
              (act): Identity()
            )
            (conv2): ConvNormLayer(
              (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
              (norm): Identity()
              (act): Identity()
            )
            (act): SiLU(inplace=True)
          )
        )
        (conv3): ConvNormLayer(
          (conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))
          (norm): Identity()
          (act): SiLU(inplace=True)
        )
      )
    )
  )
)